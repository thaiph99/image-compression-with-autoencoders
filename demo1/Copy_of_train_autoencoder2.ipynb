{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of train_autoencoder2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zItVQvmRRZaS",
        "outputId": "20357c9f-e3be-4130-ffed-2b27f86f2106"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "path = \"/content/gdrive/My Drive/image-compression-with-autoencoders/cae\"\n",
        "os.chdir(path)\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "configs   experiments  model_yt_small_final.state  requirements.txt\n",
            "datasets  LICENSE      README.md\t\t   src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEZYMAeDmbC_",
        "outputId": "529a2836-c847-4a17-be3a-08e2c939e7d7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May 21 03:50:14 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgR886twSAtt",
        "outputId": "380d0f2b-120f-452d-cf88-cf073711f996"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bagoftools\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/ee/0d7959cb8fce4fe5d27d7f19b15ee04627e53b015528c586b3b670b9f9f8/bagoftools-1.2.3-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: scikit_image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.16.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.9.1+cu101)\n",
            "Collecting colored\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/16/04827e24c14266d9161bd86bad50069fea453fa006c3d2b31da39251184a/colored-1.4.2.tar.gz (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bagoftools->-r requirements.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit_image->-r requirements.txt (line 5)) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit_image->-r requirements.txt (line 5)) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit_image->-r requirements.txt (line 5)) (2.5.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit_image->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 6)) (3.7.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bagoftools->-r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bagoftools->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bagoftools->-r requirements.txt (line 1)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bagoftools->-r requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit_image->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->bagoftools->-r requirements.txt (line 1)) (1.15.0)\n",
            "Building wheels for collected packages: colored\n",
            "  Building wheel for colored (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colored: filename=colored-1.4.2-cp37-none-any.whl size=14003 sha256=d35fe5cc9c8b2d4a77600211236837521db959feeb9b9c2d9a4a2396b04b34d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/10/5e/d17d5ef644e1051a753bd98f3796789ec39bc3337cd36637f3\n",
            "Successfully built colored\n",
            "Installing collected packages: colored, bagoftools\n",
            "Successfully installed bagoftools-1.2.3 colored-1.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLuS3EYO9IkC",
        "outputId": "393b84cb-520d-4e2b-a0f7-3e6bc95ed825"
      },
      "source": [
        "!python3 src/test.py --config configs/test.yaml"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device :  cuda\n",
            "available :  True\n",
            "test :  True\n",
            "[271][21-05-21 03:50:25.480 @ test] \u001b[38;5;4mINFO: [exp dir=/content/gdrive/My Drive/image-compression-with-autoencoders/cae/experiments/testing]\u001b[0m\n",
            "[271][21-05-21 03:50:36.950 @ test] \u001b[38;5;4mINFO: [model=model_yt_small_final.state] on cuda\u001b[0m\n",
            "[271][21-05-21 03:50:37.145 @ test] \u001b[38;5;4mINFO: [dataset=datasets/testing]\u001b[0m\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 3, 128, 128])\n",
            "shape compressed :  torch.Size([1, 32, 32, 32])\n",
            "[271][21-05-21 03:50:38.423 @ test] \u001b[38;5;5mDEBUG: [    1/    1] avg_loss: 0.003002\u001b[0m\n",
            "preshape : torch.Size([6, 128, 10, 128, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR_2i6ufSJDP",
        "outputId": "40871b8f-cbb7-454a-8975-185dfd87b435"
      },
      "source": [
        "!python3 src/train.py --config configs/train.yaml"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[283][21-05-21 03:50:41.975 @ train] \u001b[38;5;4mINFO: training: experiment training\u001b[0m\n",
            "2021-05-21 03:50:43.042837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "[283][21-05-21 03:50:44.398 @ train] \u001b[38;5;4mINFO: started tensorboard writer\u001b[0m\n",
            "[283][21-05-21 03:50:47.670 @ train] \u001b[38;5;4mINFO: loaded model on cuda\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "[283][21-05-21 03:50:55.509 @ train] \u001b[38;5;4mINFO: loaded dataset from /content/gdrive/MyDrive/image-compression-with-autoencoders/cae/datasets/training/yt_small_720p\u001b[0m\n",
            "epoch_idex : 1/4\n",
            "1->[283][21-05-21 03:51:15.689 @ train] \u001b[38;5;5mDEBUG: [  1/  3][    1/  143] avg_loss: 0.10297835\u001b[0m\n",
            "2->[283][21-05-21 03:51:25.358 @ train] \u001b[38;5;5mDEBUG: [  1/  3][    2/  143] avg_loss: 0.01997992\u001b[0m\n",
            "3->[283][21-05-21 03:51:34.921 @ train] \u001b[38;5;5mDEBUG: [  1/  3][    3/  143] avg_loss: 0.01628421\u001b[0m\n",
            "4->[283][21-05-21 03:51:44.499 @ train] \u001b[38;5;5mDEBUG: [  1/  3][    4/  143] avg_loss: 0.00896005\u001b[0m\n",
            "5->[283][21-05-21 03:51:54.142 @ train] \u001b[38;5;5mDEBUG: [  1/  3][    5/  143] avg_loss: 0.01329732\u001b[0m\n",
            "6->[283][21-05-21 03:52:03.768 @ train] \u001b[38;5;5mDEBUG: [  1/  3][    6/  143] avg_loss: 0.00931335\u001b[0m\n",
            "7->[283][21-05-21 03:52:13.526 @ train] \u001b[38;5;5mDEBUG: [  1/  3][    7/  143] avg_loss: 0.00742883\u001b[0m\n",
            "8->[283][21-05-21 03:52:23.227 @ train] \u001b[38;5;5mDEBUG: [  1/  3][    8/  143] avg_loss: 0.01015428\u001b[0m\n",
            "9->[283][21-05-21 03:52:33.009 @ train] \u001b[38;5;5mDEBUG: [  1/  3][    9/  143] avg_loss: 0.01259993\u001b[0m\n",
            "10->[283][21-05-21 03:52:42.874 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   10/  143] avg_loss: 0.00861211\u001b[0m\n",
            "11->[283][21-05-21 03:52:54.176 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   11/  143] avg_loss: 0.00879522\u001b[0m\n",
            "12->[283][21-05-21 03:53:04.040 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   12/  143] avg_loss: 0.00609910\u001b[0m\n",
            "13->[283][21-05-21 03:53:14.032 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   13/  143] avg_loss: 0.00733026\u001b[0m\n",
            "14->[283][21-05-21 03:53:24.051 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   14/  143] avg_loss: 0.00610842\u001b[0m\n",
            "15->[283][21-05-21 03:53:34.045 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   15/  143] avg_loss: 0.01317149\u001b[0m\n",
            "16->[283][21-05-21 03:53:44.188 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   16/  143] avg_loss: 0.00943502\u001b[0m\n",
            "17->[283][21-05-21 03:53:54.300 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   17/  143] avg_loss: 0.00680176\u001b[0m\n",
            "18->[283][21-05-21 03:54:04.401 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   18/  143] avg_loss: 0.01109650\u001b[0m\n",
            "19->[283][21-05-21 03:54:14.552 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   19/  143] avg_loss: 0.00805510\u001b[0m\n",
            "20->[283][21-05-21 03:54:24.672 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   20/  143] avg_loss: 0.00817445\u001b[0m\n",
            "21->[283][21-05-21 03:54:36.427 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   21/  143] avg_loss: 0.00649257\u001b[0m\n",
            "22->[283][21-05-21 03:54:46.604 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   22/  143] avg_loss: 0.00597558\u001b[0m\n",
            "23->[283][21-05-21 03:54:56.826 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   23/  143] avg_loss: 0.00803114\u001b[0m\n",
            "24->[283][21-05-21 03:55:07.051 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   24/  143] avg_loss: 0.00826958\u001b[0m\n",
            "25->[283][21-05-21 03:55:17.331 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   25/  143] avg_loss: 0.00577543\u001b[0m\n",
            "26->[283][21-05-21 03:55:27.587 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   26/  143] avg_loss: 0.00500143\u001b[0m\n",
            "27->[283][21-05-21 03:55:37.830 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   27/  143] avg_loss: 0.00470779\u001b[0m\n",
            "28->[283][21-05-21 03:55:48.165 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   28/  143] avg_loss: 0.01451337\u001b[0m\n",
            "29->[283][21-05-21 03:55:58.562 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   29/  143] avg_loss: 0.00564819\u001b[0m\n",
            "30->[283][21-05-21 03:56:08.836 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   30/  143] avg_loss: 0.00669088\u001b[0m\n",
            "31->[283][21-05-21 03:56:20.477 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   31/  143] avg_loss: 0.00768839\u001b[0m\n",
            "32->[283][21-05-21 03:56:30.854 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   32/  143] avg_loss: 0.00367771\u001b[0m\n",
            "33->[283][21-05-21 03:56:41.234 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   33/  143] avg_loss: 0.00412804\u001b[0m\n",
            "34->[283][21-05-21 03:56:51.593 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   34/  143] avg_loss: 0.00420403\u001b[0m\n",
            "35->[283][21-05-21 03:57:01.965 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   35/  143] avg_loss: 0.00341403\u001b[0m\n",
            "36->[283][21-05-21 03:57:12.482 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   36/  143] avg_loss: 0.00347019\u001b[0m\n",
            "37->[283][21-05-21 03:57:22.932 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   37/  143] avg_loss: 0.00353975\u001b[0m\n",
            "38->[283][21-05-21 03:57:33.366 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   38/  143] avg_loss: 0.00499617\u001b[0m\n",
            "39->[283][21-05-21 03:57:43.822 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   39/  143] avg_loss: 0.00293648\u001b[0m\n",
            "40->[283][21-05-21 03:57:54.366 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   40/  143] avg_loss: 0.00332730\u001b[0m\n",
            "41->[283][21-05-21 03:58:06.325 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   41/  143] avg_loss: 0.00210433\u001b[0m\n",
            "42->[283][21-05-21 03:58:16.792 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   42/  143] avg_loss: 0.00239345\u001b[0m\n",
            "43->[283][21-05-21 03:58:27.340 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   43/  143] avg_loss: 0.00276695\u001b[0m\n",
            "44->[283][21-05-21 03:58:37.831 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   44/  143] avg_loss: 0.00560783\u001b[0m\n",
            "45->[283][21-05-21 03:58:48.299 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   45/  143] avg_loss: 0.00359231\u001b[0m\n",
            "46->[283][21-05-21 03:58:58.752 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   46/  143] avg_loss: 0.00296067\u001b[0m\n",
            "47->[283][21-05-21 03:59:09.242 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   47/  143] avg_loss: 0.00243729\u001b[0m\n",
            "48->[283][21-05-21 03:59:19.711 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   48/  143] avg_loss: 0.00279093\u001b[0m\n",
            "49->[283][21-05-21 03:59:30.206 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   49/  143] avg_loss: 0.00176556\u001b[0m\n",
            "50->[283][21-05-21 03:59:40.724 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   50/  143] avg_loss: 0.00271232\u001b[0m\n",
            "51->[283][21-05-21 03:59:52.675 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   51/  143] avg_loss: 0.00270234\u001b[0m\n",
            "52->[283][21-05-21 04:00:03.177 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   52/  143] avg_loss: 0.00522383\u001b[0m\n",
            "53->[283][21-05-21 04:00:13.741 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   53/  143] avg_loss: 0.00272358\u001b[0m\n",
            "54->[283][21-05-21 04:00:24.315 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   54/  143] avg_loss: 0.00210788\u001b[0m\n",
            "55->[283][21-05-21 04:00:34.852 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   55/  143] avg_loss: 0.00463302\u001b[0m\n",
            "56->[283][21-05-21 04:00:45.483 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   56/  143] avg_loss: 0.00358285\u001b[0m\n",
            "57->[283][21-05-21 04:00:56.045 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   57/  143] avg_loss: 0.00250924\u001b[0m\n",
            "58->[283][21-05-21 04:01:06.556 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   58/  143] avg_loss: 0.00307606\u001b[0m\n",
            "59->[283][21-05-21 04:01:17.087 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   59/  143] avg_loss: 0.00192810\u001b[0m\n",
            "60->[283][21-05-21 04:01:27.588 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   60/  143] avg_loss: 0.00161034\u001b[0m\n",
            "61->[283][21-05-21 04:01:39.394 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   61/  143] avg_loss: 0.00207343\u001b[0m\n",
            "62->[283][21-05-21 04:01:49.843 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   62/  143] avg_loss: 0.00277666\u001b[0m\n",
            "63->[283][21-05-21 04:02:00.452 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   63/  143] avg_loss: 0.00318793\u001b[0m\n",
            "64->[283][21-05-21 04:02:10.962 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   64/  143] avg_loss: 0.00244272\u001b[0m\n",
            "65->[283][21-05-21 04:02:21.496 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   65/  143] avg_loss: 0.00299407\u001b[0m\n",
            "66->[283][21-05-21 04:02:32.013 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   66/  143] avg_loss: 0.00245113\u001b[0m\n",
            "67->[283][21-05-21 04:02:42.540 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   67/  143] avg_loss: 0.00287394\u001b[0m\n",
            "68->[283][21-05-21 04:02:53.086 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   68/  143] avg_loss: 0.00284573\u001b[0m\n",
            "69->[283][21-05-21 04:03:03.594 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   69/  143] avg_loss: 0.00222590\u001b[0m\n",
            "70->[283][21-05-21 04:03:14.103 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   70/  143] avg_loss: 0.00254434\u001b[0m\n",
            "71->[283][21-05-21 04:03:26.116 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   71/  143] avg_loss: 0.00277150\u001b[0m\n",
            "72->[283][21-05-21 04:03:36.696 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   72/  143] avg_loss: 0.00314546\u001b[0m\n",
            "73->[283][21-05-21 04:03:47.233 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   73/  143] avg_loss: 0.00268740\u001b[0m\n",
            "74->[283][21-05-21 04:03:57.765 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   74/  143] avg_loss: 0.00179121\u001b[0m\n",
            "75->[283][21-05-21 04:04:08.317 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   75/  143] avg_loss: 0.00203374\u001b[0m\n",
            "76->[283][21-05-21 04:04:18.860 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   76/  143] avg_loss: 0.00215434\u001b[0m\n",
            "77->[283][21-05-21 04:04:29.389 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   77/  143] avg_loss: 0.00194957\u001b[0m\n",
            "78->[283][21-05-21 04:04:39.888 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   78/  143] avg_loss: 0.00340887\u001b[0m\n",
            "79->[283][21-05-21 04:04:50.427 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   79/  143] avg_loss: 0.00215676\u001b[0m\n",
            "80->[283][21-05-21 04:05:00.916 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   80/  143] avg_loss: 0.00305020\u001b[0m\n",
            "81->[283][21-05-21 04:05:12.852 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   81/  143] avg_loss: 0.00206167\u001b[0m\n",
            "82->[283][21-05-21 04:05:23.288 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   82/  143] avg_loss: 0.00173430\u001b[0m\n",
            "83->[283][21-05-21 04:05:33.809 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   83/  143] avg_loss: 0.00251827\u001b[0m\n",
            "84->[283][21-05-21 04:05:44.274 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   84/  143] avg_loss: 0.00250293\u001b[0m\n",
            "85->[283][21-05-21 04:05:54.731 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   85/  143] avg_loss: 0.00235379\u001b[0m\n",
            "86->[283][21-05-21 04:06:05.276 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   86/  143] avg_loss: 0.00206472\u001b[0m\n",
            "87->[283][21-05-21 04:06:15.798 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   87/  143] avg_loss: 0.00198209\u001b[0m\n",
            "88->[283][21-05-21 04:06:26.283 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   88/  143] avg_loss: 0.00232930\u001b[0m\n",
            "89->[283][21-05-21 04:06:36.786 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   89/  143] avg_loss: 0.00227222\u001b[0m\n",
            "90->[283][21-05-21 04:06:47.278 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   90/  143] avg_loss: 0.00208302\u001b[0m\n",
            "91->[283][21-05-21 04:06:59.351 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   91/  143] avg_loss: 0.00181146\u001b[0m\n",
            "92->[283][21-05-21 04:07:09.922 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   92/  143] avg_loss: 0.00199541\u001b[0m\n",
            "93->[283][21-05-21 04:07:20.441 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   93/  143] avg_loss: 0.00227736\u001b[0m\n",
            "94->[283][21-05-21 04:07:30.923 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   94/  143] avg_loss: 0.00235569\u001b[0m\n",
            "95->[283][21-05-21 04:07:41.445 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   95/  143] avg_loss: 0.00317455\u001b[0m\n",
            "96->[283][21-05-21 04:07:51.974 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   96/  143] avg_loss: 0.00213463\u001b[0m\n",
            "97->[283][21-05-21 04:08:02.451 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   97/  143] avg_loss: 0.00224314\u001b[0m\n",
            "98->[283][21-05-21 04:08:12.912 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   98/  143] avg_loss: 0.00364102\u001b[0m\n",
            "99->[283][21-05-21 04:08:23.386 @ train] \u001b[38;5;5mDEBUG: [  1/  3][   99/  143] avg_loss: 0.00267513\u001b[0m\n",
            "100->[283][21-05-21 04:08:33.863 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  100/  143] avg_loss: 0.00220928\u001b[0m\n",
            "101->[283][21-05-21 04:08:46.015 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  101/  143] avg_loss: 0.00229978\u001b[0m\n",
            "102->[283][21-05-21 04:08:56.550 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  102/  143] avg_loss: 0.00208499\u001b[0m\n",
            "103->[283][21-05-21 04:09:07.065 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  103/  143] avg_loss: 0.00227857\u001b[0m\n",
            "104->[283][21-05-21 04:09:17.584 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  104/  143] avg_loss: 0.00218195\u001b[0m\n",
            "105->[283][21-05-21 04:09:28.179 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  105/  143] avg_loss: 0.00215925\u001b[0m\n",
            "106->[283][21-05-21 04:09:38.693 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  106/  143] avg_loss: 0.00169189\u001b[0m\n",
            "107->[283][21-05-21 04:09:49.207 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  107/  143] avg_loss: 0.00458376\u001b[0m\n",
            "108->[283][21-05-21 04:09:59.722 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  108/  143] avg_loss: 0.00266105\u001b[0m\n",
            "109->[283][21-05-21 04:10:10.229 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  109/  143] avg_loss: 0.00235792\u001b[0m\n",
            "110->[283][21-05-21 04:10:20.754 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  110/  143] avg_loss: 0.00181363\u001b[0m\n",
            "111->[283][21-05-21 04:10:32.648 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  111/  143] avg_loss: 0.00269712\u001b[0m\n",
            "112->[283][21-05-21 04:10:43.105 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  112/  143] avg_loss: 0.00345193\u001b[0m\n",
            "113->[283][21-05-21 04:10:53.579 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  113/  143] avg_loss: 0.00173732\u001b[0m\n",
            "114->[283][21-05-21 04:11:04.108 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  114/  143] avg_loss: 0.00253616\u001b[0m\n",
            "115->[283][21-05-21 04:11:14.598 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  115/  143] avg_loss: 0.00172805\u001b[0m\n",
            "116->[283][21-05-21 04:11:25.099 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  116/  143] avg_loss: 0.00178754\u001b[0m\n",
            "117->[283][21-05-21 04:11:35.609 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  117/  143] avg_loss: 0.00261444\u001b[0m\n",
            "118->[283][21-05-21 04:11:46.061 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  118/  143] avg_loss: 0.00203352\u001b[0m\n",
            "119->[283][21-05-21 04:11:56.560 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  119/  143] avg_loss: 0.00215382\u001b[0m\n",
            "120->[283][21-05-21 04:12:07.070 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  120/  143] avg_loss: 0.00171908\u001b[0m\n",
            "121->[283][21-05-21 04:12:18.886 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  121/  143] avg_loss: 0.00246178\u001b[0m\n",
            "122->[283][21-05-21 04:12:29.402 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  122/  143] avg_loss: 0.00138161\u001b[0m\n",
            "123->[283][21-05-21 04:12:39.893 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  123/  143] avg_loss: 0.00187783\u001b[0m\n",
            "124->[283][21-05-21 04:12:50.417 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  124/  143] avg_loss: 0.00217777\u001b[0m\n",
            "125->[283][21-05-21 04:13:00.932 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  125/  143] avg_loss: 0.00235402\u001b[0m\n",
            "126->[283][21-05-21 04:13:11.420 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  126/  143] avg_loss: 0.00213293\u001b[0m\n",
            "127->[283][21-05-21 04:13:21.947 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  127/  143] avg_loss: 0.00211721\u001b[0m\n",
            "128->[283][21-05-21 04:13:32.515 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  128/  143] avg_loss: 0.00344279\u001b[0m\n",
            "129->[283][21-05-21 04:13:43.003 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  129/  143] avg_loss: 0.00219557\u001b[0m\n",
            "130->[283][21-05-21 04:13:53.553 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  130/  143] avg_loss: 0.00334544\u001b[0m\n",
            "131->[283][21-05-21 04:14:05.441 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  131/  143] avg_loss: 0.00163054\u001b[0m\n",
            "132->[283][21-05-21 04:14:15.926 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  132/  143] avg_loss: 0.00274018\u001b[0m\n",
            "133->[283][21-05-21 04:14:26.517 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  133/  143] avg_loss: 0.00178336\u001b[0m\n",
            "134->[283][21-05-21 04:14:36.929 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  134/  143] avg_loss: 0.00181591\u001b[0m\n",
            "135->[283][21-05-21 04:14:47.414 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  135/  143] avg_loss: 0.00277660\u001b[0m\n",
            "136->[283][21-05-21 04:14:57.831 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  136/  143] avg_loss: 0.00190841\u001b[0m\n",
            "137->[283][21-05-21 04:15:08.288 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  137/  143] avg_loss: 0.00189433\u001b[0m\n",
            "138->[283][21-05-21 04:15:18.733 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  138/  143] avg_loss: 0.00109612\u001b[0m\n",
            "139->[283][21-05-21 04:15:29.162 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  139/  143] avg_loss: 0.00257783\u001b[0m\n",
            "140->[283][21-05-21 04:15:39.583 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  140/  143] avg_loss: 0.00193929\u001b[0m\n",
            "141->[283][21-05-21 04:15:51.029 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  141/  143] avg_loss: 0.00175221\u001b[0m\n",
            "142->[283][21-05-21 04:16:01.408 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  142/  143] avg_loss: 0.00179087\u001b[0m\n",
            "143->[283][21-05-21 04:16:10.196 @ train] \u001b[38;5;5mDEBUG: [  1/  3][  143/  143] avg_loss: 0.00211759\u001b[0m\n",
            "[283][21-05-21 04:16:10.385 @ train] \u001b[38;5;4mINFO: Epoch avg = 0.00461720\u001b[0m\n",
            "epoch_idex : 2/4\n",
            "1->[283][21-05-21 04:16:28.141 @ train] \u001b[38;5;5mDEBUG: [  2/  3][    1/  143] avg_loss: 0.00195485\u001b[0m\n",
            "2->[283][21-05-21 04:16:38.507 @ train] \u001b[38;5;5mDEBUG: [  2/  3][    2/  143] avg_loss: 0.00239904\u001b[0m\n",
            "3->[283][21-05-21 04:16:48.944 @ train] \u001b[38;5;5mDEBUG: [  2/  3][    3/  143] avg_loss: 0.00140736\u001b[0m\n",
            "4->[283][21-05-21 04:16:59.470 @ train] \u001b[38;5;5mDEBUG: [  2/  3][    4/  143] avg_loss: 0.00206812\u001b[0m\n",
            "5->[283][21-05-21 04:17:09.956 @ train] \u001b[38;5;5mDEBUG: [  2/  3][    5/  143] avg_loss: 0.00156215\u001b[0m\n",
            "6->[283][21-05-21 04:17:20.429 @ train] \u001b[38;5;5mDEBUG: [  2/  3][    6/  143] avg_loss: 0.00192544\u001b[0m\n",
            "7->[283][21-05-21 04:17:30.827 @ train] \u001b[38;5;5mDEBUG: [  2/  3][    7/  143] avg_loss: 0.00152384\u001b[0m\n",
            "8->[283][21-05-21 04:17:41.299 @ train] \u001b[38;5;5mDEBUG: [  2/  3][    8/  143] avg_loss: 0.00265947\u001b[0m\n",
            "9->[283][21-05-21 04:17:51.750 @ train] \u001b[38;5;5mDEBUG: [  2/  3][    9/  143] avg_loss: 0.00332510\u001b[0m\n",
            "10->[283][21-05-21 04:18:02.193 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   10/  143] avg_loss: 0.00230424\u001b[0m\n",
            "11->[283][21-05-21 04:18:13.748 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   11/  143] avg_loss: 0.00196088\u001b[0m\n",
            "12->[283][21-05-21 04:18:24.255 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   12/  143] avg_loss: 0.00265695\u001b[0m\n",
            "13->[283][21-05-21 04:18:34.683 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   13/  143] avg_loss: 0.00121568\u001b[0m\n",
            "14->[283][21-05-21 04:18:45.135 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   14/  143] avg_loss: 0.00483867\u001b[0m\n",
            "15->[283][21-05-21 04:18:55.627 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   15/  143] avg_loss: 0.00445757\u001b[0m\n",
            "16->[283][21-05-21 04:19:06.117 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   16/  143] avg_loss: 0.00271410\u001b[0m\n",
            "17->[283][21-05-21 04:19:16.599 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   17/  143] avg_loss: 0.00177398\u001b[0m\n",
            "18->[283][21-05-21 04:19:27.097 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   18/  143] avg_loss: 0.00115764\u001b[0m\n",
            "19->[283][21-05-21 04:19:37.562 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   19/  143] avg_loss: 0.00127477\u001b[0m\n",
            "20->[283][21-05-21 04:19:48.056 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   20/  143] avg_loss: 0.00161331\u001b[0m\n",
            "21->[283][21-05-21 04:19:59.542 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   21/  143] avg_loss: 0.00112924\u001b[0m\n",
            "22->[283][21-05-21 04:20:09.974 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   22/  143] avg_loss: 0.00120580\u001b[0m\n",
            "23->[283][21-05-21 04:20:20.410 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   23/  143] avg_loss: 0.00156636\u001b[0m\n",
            "24->[283][21-05-21 04:20:30.894 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   24/  143] avg_loss: 0.00192430\u001b[0m\n",
            "25->[283][21-05-21 04:20:41.336 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   25/  143] avg_loss: 0.00164830\u001b[0m\n",
            "26->[283][21-05-21 04:20:51.799 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   26/  143] avg_loss: 0.00217776\u001b[0m\n",
            "27->[283][21-05-21 04:21:02.229 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   27/  143] avg_loss: 0.00544991\u001b[0m\n",
            "28->[283][21-05-21 04:21:12.671 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   28/  143] avg_loss: 0.00181276\u001b[0m\n",
            "29->[283][21-05-21 04:21:23.153 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   29/  143] avg_loss: 0.00170075\u001b[0m\n",
            "30->[283][21-05-21 04:21:33.645 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   30/  143] avg_loss: 0.00510597\u001b[0m\n",
            "31->[283][21-05-21 04:21:44.990 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   31/  143] avg_loss: 0.00190300\u001b[0m\n",
            "32->[283][21-05-21 04:21:55.460 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   32/  143] avg_loss: 0.00148696\u001b[0m\n",
            "33->[283][21-05-21 04:22:05.952 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   33/  143] avg_loss: 0.00121380\u001b[0m\n",
            "34->[283][21-05-21 04:22:16.441 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   34/  143] avg_loss: 0.00178826\u001b[0m\n",
            "35->[283][21-05-21 04:22:26.911 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   35/  143] avg_loss: 0.00153421\u001b[0m\n",
            "36->[283][21-05-21 04:22:37.408 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   36/  143] avg_loss: 0.00156200\u001b[0m\n",
            "37->[283][21-05-21 04:22:47.885 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   37/  143] avg_loss: 0.00158285\u001b[0m\n",
            "38->[283][21-05-21 04:22:58.365 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   38/  143] avg_loss: 0.00127420\u001b[0m\n",
            "39->[283][21-05-21 04:23:08.862 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   39/  143] avg_loss: 0.00138880\u001b[0m\n",
            "40->[283][21-05-21 04:23:19.369 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   40/  143] avg_loss: 0.00118413\u001b[0m\n",
            "41->[283][21-05-21 04:23:31.012 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   41/  143] avg_loss: 0.00142423\u001b[0m\n",
            "42->[283][21-05-21 04:23:41.480 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   42/  143] avg_loss: 0.00188705\u001b[0m\n",
            "43->[283][21-05-21 04:23:51.954 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   43/  143] avg_loss: 0.00110502\u001b[0m\n",
            "44->[283][21-05-21 04:24:02.400 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   44/  143] avg_loss: 0.00138835\u001b[0m\n",
            "45->[283][21-05-21 04:24:12.863 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   45/  143] avg_loss: 0.00139528\u001b[0m\n",
            "46->[283][21-05-21 04:24:23.387 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   46/  143] avg_loss: 0.00116468\u001b[0m\n",
            "47->[283][21-05-21 04:24:33.838 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   47/  143] avg_loss: 0.00160896\u001b[0m\n",
            "48->[283][21-05-21 04:24:44.281 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   48/  143] avg_loss: 0.00091971\u001b[0m\n",
            "49->[283][21-05-21 04:24:54.764 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   49/  143] avg_loss: 0.00161087\u001b[0m\n",
            "50->[283][21-05-21 04:25:05.201 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   50/  143] avg_loss: 0.00154281\u001b[0m\n",
            "51->[283][21-05-21 04:25:16.745 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   51/  143] avg_loss: 0.00083317\u001b[0m\n",
            "52->[283][21-05-21 04:25:27.229 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   52/  143] avg_loss: 0.00207199\u001b[0m\n",
            "53->[283][21-05-21 04:25:37.731 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   53/  143] avg_loss: 0.00126803\u001b[0m\n",
            "54->[283][21-05-21 04:25:48.279 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   54/  143] avg_loss: 0.00108332\u001b[0m\n",
            "55->[283][21-05-21 04:25:58.789 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   55/  143] avg_loss: 0.00087319\u001b[0m\n",
            "56->[283][21-05-21 04:26:09.256 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   56/  143] avg_loss: 0.00122007\u001b[0m\n",
            "57->[283][21-05-21 04:26:19.759 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   57/  143] avg_loss: 0.00177052\u001b[0m\n",
            "58->[283][21-05-21 04:26:30.249 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   58/  143] avg_loss: 0.00110891\u001b[0m\n",
            "59->[283][21-05-21 04:26:40.740 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   59/  143] avg_loss: 0.00105494\u001b[0m\n",
            "60->[283][21-05-21 04:26:51.239 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   60/  143] avg_loss: 0.00121085\u001b[0m\n",
            "61->[283][21-05-21 04:27:02.384 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   61/  143] avg_loss: 0.00106682\u001b[0m\n",
            "62->[283][21-05-21 04:27:12.910 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   62/  143] avg_loss: 0.00091425\u001b[0m\n",
            "63->[283][21-05-21 04:27:23.347 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   63/  143] avg_loss: 0.00153764\u001b[0m\n",
            "64->[283][21-05-21 04:27:33.850 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   64/  143] avg_loss: 0.00127355\u001b[0m\n",
            "65->[283][21-05-21 04:27:44.336 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   65/  143] avg_loss: 0.00158161\u001b[0m\n",
            "66->[283][21-05-21 04:27:54.873 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   66/  143] avg_loss: 0.00100965\u001b[0m\n",
            "67->[283][21-05-21 04:28:05.356 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   67/  143] avg_loss: 0.00134905\u001b[0m\n",
            "68->[283][21-05-21 04:28:15.870 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   68/  143] avg_loss: 0.00165169\u001b[0m\n",
            "69->[283][21-05-21 04:28:26.344 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   69/  143] avg_loss: 0.00104601\u001b[0m\n",
            "70->[283][21-05-21 04:28:36.782 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   70/  143] avg_loss: 0.00135462\u001b[0m\n",
            "71->[283][21-05-21 04:28:48.196 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   71/  143] avg_loss: 0.00094231\u001b[0m\n",
            "72->[283][21-05-21 04:28:58.654 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   72/  143] avg_loss: 0.00108012\u001b[0m\n",
            "73->[283][21-05-21 04:29:09.118 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   73/  143] avg_loss: 0.00086762\u001b[0m\n",
            "74->[283][21-05-21 04:29:19.645 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   74/  143] avg_loss: 0.00107571\u001b[0m\n",
            "75->[283][21-05-21 04:29:30.144 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   75/  143] avg_loss: 0.00095661\u001b[0m\n",
            "76->[283][21-05-21 04:29:40.620 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   76/  143] avg_loss: 0.00101451\u001b[0m\n",
            "77->[283][21-05-21 04:29:51.080 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   77/  143] avg_loss: 0.00162181\u001b[0m\n",
            "78->[283][21-05-21 04:30:01.547 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   78/  143] avg_loss: 0.00093934\u001b[0m\n",
            "79->[283][21-05-21 04:30:12.066 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   79/  143] avg_loss: 0.00156229\u001b[0m\n",
            "80->[283][21-05-21 04:30:22.522 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   80/  143] avg_loss: 0.00146187\u001b[0m\n",
            "81->[283][21-05-21 04:30:33.948 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   81/  143] avg_loss: 0.00115005\u001b[0m\n",
            "82->[283][21-05-21 04:30:44.462 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   82/  143] avg_loss: 0.00098080\u001b[0m\n",
            "83->[283][21-05-21 04:30:54.923 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   83/  143] avg_loss: 0.00095602\u001b[0m\n",
            "84->[283][21-05-21 04:31:05.472 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   84/  143] avg_loss: 0.00131221\u001b[0m\n",
            "85->[283][21-05-21 04:31:15.946 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   85/  143] avg_loss: 0.00108276\u001b[0m\n",
            "86->[283][21-05-21 04:31:26.409 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   86/  143] avg_loss: 0.00111066\u001b[0m\n",
            "87->[283][21-05-21 04:31:36.843 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   87/  143] avg_loss: 0.00101827\u001b[0m\n",
            "88->[283][21-05-21 04:31:47.345 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   88/  143] avg_loss: 0.00103185\u001b[0m\n",
            "89->[283][21-05-21 04:31:57.812 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   89/  143] avg_loss: 0.00092960\u001b[0m\n",
            "90->[283][21-05-21 04:32:08.321 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   90/  143] avg_loss: 0.00118552\u001b[0m\n",
            "91->[283][21-05-21 04:32:19.790 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   91/  143] avg_loss: 0.00114640\u001b[0m\n",
            "92->[283][21-05-21 04:32:30.222 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   92/  143] avg_loss: 0.00178816\u001b[0m\n",
            "93->[283][21-05-21 04:32:40.674 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   93/  143] avg_loss: 0.00117435\u001b[0m\n",
            "94->[283][21-05-21 04:32:51.152 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   94/  143] avg_loss: 0.00081455\u001b[0m\n",
            "95->[283][21-05-21 04:33:01.615 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   95/  143] avg_loss: 0.00149763\u001b[0m\n",
            "96->[283][21-05-21 04:33:12.111 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   96/  143] avg_loss: 0.00127613\u001b[0m\n",
            "97->[283][21-05-21 04:33:22.599 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   97/  143] avg_loss: 0.00111393\u001b[0m\n",
            "98->[283][21-05-21 04:33:33.059 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   98/  143] avg_loss: 0.00123586\u001b[0m\n",
            "99->[283][21-05-21 04:33:43.417 @ train] \u001b[38;5;5mDEBUG: [  2/  3][   99/  143] avg_loss: 0.00076498\u001b[0m\n",
            "100->[283][21-05-21 04:33:53.887 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  100/  143] avg_loss: 0.00119149\u001b[0m\n",
            "101->[283][21-05-21 04:34:05.161 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  101/  143] avg_loss: 0.00124000\u001b[0m\n",
            "102->[283][21-05-21 04:34:15.637 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  102/  143] avg_loss: 0.00067173\u001b[0m\n",
            "103->[283][21-05-21 04:34:26.114 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  103/  143] avg_loss: 0.00136647\u001b[0m\n",
            "104->[283][21-05-21 04:34:36.579 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  104/  143] avg_loss: 0.00092176\u001b[0m\n",
            "105->[283][21-05-21 04:34:46.990 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  105/  143] avg_loss: 0.00102733\u001b[0m\n",
            "106->[283][21-05-21 04:34:57.470 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  106/  143] avg_loss: 0.00089811\u001b[0m\n",
            "107->[283][21-05-21 04:35:07.927 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  107/  143] avg_loss: 0.00091691\u001b[0m\n",
            "108->[283][21-05-21 04:35:18.371 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  108/  143] avg_loss: 0.00106429\u001b[0m\n",
            "109->[283][21-05-21 04:35:28.838 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  109/  143] avg_loss: 0.00126928\u001b[0m\n",
            "110->[283][21-05-21 04:35:39.319 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  110/  143] avg_loss: 0.00104158\u001b[0m\n",
            "111->[283][21-05-21 04:35:50.778 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  111/  143] avg_loss: 0.00115806\u001b[0m\n",
            "112->[283][21-05-21 04:36:01.234 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  112/  143] avg_loss: 0.00119285\u001b[0m\n",
            "113->[283][21-05-21 04:36:11.680 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  113/  143] avg_loss: 0.00104535\u001b[0m\n",
            "114->[283][21-05-21 04:36:22.121 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  114/  143] avg_loss: 0.00094908\u001b[0m\n",
            "115->[283][21-05-21 04:36:32.573 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  115/  143] avg_loss: 0.00088942\u001b[0m\n",
            "116->[283][21-05-21 04:36:43.084 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  116/  143] avg_loss: 0.00086230\u001b[0m\n",
            "117->[283][21-05-21 04:36:53.547 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  117/  143] avg_loss: 0.00160485\u001b[0m\n",
            "118->[283][21-05-21 04:37:03.991 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  118/  143] avg_loss: 0.00126312\u001b[0m\n",
            "119->[283][21-05-21 04:37:14.456 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  119/  143] avg_loss: 0.00118195\u001b[0m\n",
            "120->[283][21-05-21 04:37:24.963 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  120/  143] avg_loss: 0.00127624\u001b[0m\n",
            "121->[283][21-05-21 04:37:36.418 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  121/  143] avg_loss: 0.00113201\u001b[0m\n",
            "122->[283][21-05-21 04:37:46.932 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  122/  143] avg_loss: 0.00131626\u001b[0m\n",
            "123->[283][21-05-21 04:37:57.407 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  123/  143] avg_loss: 0.00098807\u001b[0m\n",
            "124->[283][21-05-21 04:38:07.892 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  124/  143] avg_loss: 0.00122416\u001b[0m\n",
            "125->[283][21-05-21 04:38:18.376 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  125/  143] avg_loss: 0.00115512\u001b[0m\n",
            "126->[283][21-05-21 04:38:28.857 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  126/  143] avg_loss: 0.00128384\u001b[0m\n",
            "127->[283][21-05-21 04:38:39.300 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  127/  143] avg_loss: 0.00147269\u001b[0m\n",
            "128->[283][21-05-21 04:38:49.766 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  128/  143] avg_loss: 0.00080662\u001b[0m\n",
            "129->[283][21-05-21 04:39:00.240 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  129/  143] avg_loss: 0.00102152\u001b[0m\n",
            "130->[283][21-05-21 04:39:10.710 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  130/  143] avg_loss: 0.00127813\u001b[0m\n",
            "131->[283][21-05-21 04:39:22.007 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  131/  143] avg_loss: 0.00072942\u001b[0m\n",
            "132->[283][21-05-21 04:39:32.464 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  132/  143] avg_loss: 0.00102516\u001b[0m\n",
            "133->[283][21-05-21 04:39:42.949 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  133/  143] avg_loss: 0.00099253\u001b[0m\n",
            "134->[283][21-05-21 04:39:53.431 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  134/  143] avg_loss: 0.00105704\u001b[0m\n",
            "135->[283][21-05-21 04:40:03.902 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  135/  143] avg_loss: 0.00131255\u001b[0m\n",
            "136->[283][21-05-21 04:40:14.368 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  136/  143] avg_loss: 0.00107279\u001b[0m\n",
            "137->[283][21-05-21 04:40:24.795 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  137/  143] avg_loss: 0.00119831\u001b[0m\n",
            "138->[283][21-05-21 04:40:35.231 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  138/  143] avg_loss: 0.00095893\u001b[0m\n",
            "139->[283][21-05-21 04:40:45.651 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  139/  143] avg_loss: 0.00160013\u001b[0m\n",
            "140->[283][21-05-21 04:40:56.092 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  140/  143] avg_loss: 0.00081820\u001b[0m\n",
            "141->[283][21-05-21 04:41:07.163 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  141/  143] avg_loss: 0.00091360\u001b[0m\n",
            "142->[283][21-05-21 04:41:17.587 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  142/  143] avg_loss: 0.00134373\u001b[0m\n",
            "143->[283][21-05-21 04:41:26.419 @ train] \u001b[38;5;5mDEBUG: [  2/  3][  143/  143] avg_loss: 0.00075846\u001b[0m\n",
            "[283][21-05-21 04:41:26.587 @ train] \u001b[38;5;4mINFO: Epoch avg = 0.00142897\u001b[0m\n",
            "epoch_idex : 3/4\n",
            "1->[283][21-05-21 04:41:43.521 @ train] \u001b[38;5;5mDEBUG: [  3/  3][    1/  143] avg_loss: 0.00107858\u001b[0m\n",
            "2->[283][21-05-21 04:41:53.945 @ train] \u001b[38;5;5mDEBUG: [  3/  3][    2/  143] avg_loss: 0.00108597\u001b[0m\n",
            "3->[283][21-05-21 04:42:04.410 @ train] \u001b[38;5;5mDEBUG: [  3/  3][    3/  143] avg_loss: 0.00076318\u001b[0m\n",
            "4->[283][21-05-21 04:42:14.883 @ train] \u001b[38;5;5mDEBUG: [  3/  3][    4/  143] avg_loss: 0.00081974\u001b[0m\n",
            "5->[283][21-05-21 04:42:25.331 @ train] \u001b[38;5;5mDEBUG: [  3/  3][    5/  143] avg_loss: 0.00094890\u001b[0m\n",
            "6->[283][21-05-21 04:42:35.830 @ train] \u001b[38;5;5mDEBUG: [  3/  3][    6/  143] avg_loss: 0.00089390\u001b[0m\n",
            "7->[283][21-05-21 04:42:46.287 @ train] \u001b[38;5;5mDEBUG: [  3/  3][    7/  143] avg_loss: 0.00142150\u001b[0m\n",
            "8->[283][21-05-21 04:42:56.702 @ train] \u001b[38;5;5mDEBUG: [  3/  3][    8/  143] avg_loss: 0.00101943\u001b[0m\n",
            "9->[283][21-05-21 04:43:07.163 @ train] \u001b[38;5;5mDEBUG: [  3/  3][    9/  143] avg_loss: 0.00111310\u001b[0m\n",
            "10->[283][21-05-21 04:43:17.573 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   10/  143] avg_loss: 0.00144175\u001b[0m\n",
            "11->[283][21-05-21 04:43:29.109 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   11/  143] avg_loss: 0.00079932\u001b[0m\n",
            "12->[283][21-05-21 04:43:39.588 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   12/  143] avg_loss: 0.00171613\u001b[0m\n",
            "13->[283][21-05-21 04:43:50.060 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   13/  143] avg_loss: 0.00115087\u001b[0m\n",
            "14->[283][21-05-21 04:44:00.517 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   14/  143] avg_loss: 0.00115805\u001b[0m\n",
            "15->[283][21-05-21 04:44:10.998 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   15/  143] avg_loss: 0.00133554\u001b[0m\n",
            "16->[283][21-05-21 04:44:21.415 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   16/  143] avg_loss: 0.00094696\u001b[0m\n",
            "17->[283][21-05-21 04:44:31.924 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   17/  143] avg_loss: 0.00081552\u001b[0m\n",
            "18->[283][21-05-21 04:44:42.398 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   18/  143] avg_loss: 0.00098448\u001b[0m\n",
            "19->[283][21-05-21 04:44:52.878 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   19/  143] avg_loss: 0.00108649\u001b[0m\n",
            "20->[283][21-05-21 04:45:03.361 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   20/  143] avg_loss: 0.00113988\u001b[0m\n",
            "21->[283][21-05-21 04:45:14.767 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   21/  143] avg_loss: 0.00102490\u001b[0m\n",
            "22->[283][21-05-21 04:45:25.216 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   22/  143] avg_loss: 0.00082358\u001b[0m\n",
            "23->[283][21-05-21 04:45:35.697 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   23/  143] avg_loss: 0.00151706\u001b[0m\n",
            "24->[283][21-05-21 04:45:46.181 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   24/  143] avg_loss: 0.00073303\u001b[0m\n",
            "25->[283][21-05-21 04:45:56.645 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   25/  143] avg_loss: 0.00078380\u001b[0m\n",
            "26->[283][21-05-21 04:46:07.113 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   26/  143] avg_loss: 0.00104481\u001b[0m\n",
            "27->[283][21-05-21 04:46:17.639 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   27/  143] avg_loss: 0.00085008\u001b[0m\n",
            "28->[283][21-05-21 04:46:28.102 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   28/  143] avg_loss: 0.00149837\u001b[0m\n",
            "29->[283][21-05-21 04:46:38.579 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   29/  143] avg_loss: 0.00096684\u001b[0m\n",
            "30->[283][21-05-21 04:46:49.070 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   30/  143] avg_loss: 0.00101633\u001b[0m\n",
            "31->[283][21-05-21 04:47:00.663 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   31/  143] avg_loss: 0.00079273\u001b[0m\n",
            "32->[283][21-05-21 04:47:11.162 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   32/  143] avg_loss: 0.00127355\u001b[0m\n",
            "33->[283][21-05-21 04:47:21.646 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   33/  143] avg_loss: 0.00106903\u001b[0m\n",
            "34->[283][21-05-21 04:47:32.101 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   34/  143] avg_loss: 0.00090590\u001b[0m\n",
            "35->[283][21-05-21 04:47:42.572 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   35/  143] avg_loss: 0.00122712\u001b[0m\n",
            "36->[283][21-05-21 04:47:53.057 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   36/  143] avg_loss: 0.00091872\u001b[0m\n",
            "37->[283][21-05-21 04:48:03.551 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   37/  143] avg_loss: 0.00083884\u001b[0m\n",
            "38->[283][21-05-21 04:48:14.026 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   38/  143] avg_loss: 0.00080097\u001b[0m\n",
            "39->[283][21-05-21 04:48:24.462 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   39/  143] avg_loss: 0.00133520\u001b[0m\n",
            "40->[283][21-05-21 04:48:34.922 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   40/  143] avg_loss: 0.00093585\u001b[0m\n",
            "41->[283][21-05-21 04:48:46.316 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   41/  143] avg_loss: 0.00101139\u001b[0m\n",
            "42->[283][21-05-21 04:48:56.767 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   42/  143] avg_loss: 0.00086123\u001b[0m\n",
            "43->[283][21-05-21 04:49:07.253 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   43/  143] avg_loss: 0.00110074\u001b[0m\n",
            "44->[283][21-05-21 04:49:17.792 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   44/  143] avg_loss: 0.00099197\u001b[0m\n",
            "45->[283][21-05-21 04:49:28.324 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   45/  143] avg_loss: 0.00086308\u001b[0m\n",
            "46->[283][21-05-21 04:49:38.758 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   46/  143] avg_loss: 0.00106348\u001b[0m\n",
            "47->[283][21-05-21 04:49:49.209 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   47/  143] avg_loss: 0.00089195\u001b[0m\n",
            "48->[283][21-05-21 04:49:59.708 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   48/  143] avg_loss: 0.00149925\u001b[0m\n",
            "49->[283][21-05-21 04:50:10.177 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   49/  143] avg_loss: 0.00083587\u001b[0m\n",
            "50->[283][21-05-21 04:50:20.679 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   50/  143] avg_loss: 0.00103824\u001b[0m\n",
            "51->[283][21-05-21 04:50:32.076 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   51/  143] avg_loss: 0.00105423\u001b[0m\n",
            "52->[283][21-05-21 04:50:42.517 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   52/  143] avg_loss: 0.00073115\u001b[0m\n",
            "53->[283][21-05-21 04:50:53.024 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   53/  143] avg_loss: 0.00064267\u001b[0m\n",
            "54->[283][21-05-21 04:51:03.500 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   54/  143] avg_loss: 0.00066884\u001b[0m\n",
            "55->[283][21-05-21 04:51:13.983 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   55/  143] avg_loss: 0.00087945\u001b[0m\n",
            "56->[283][21-05-21 04:51:24.410 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   56/  143] avg_loss: 0.00088251\u001b[0m\n",
            "57->[283][21-05-21 04:51:34.889 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   57/  143] avg_loss: 0.00126266\u001b[0m\n",
            "58->[283][21-05-21 04:51:45.367 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   58/  143] avg_loss: 0.00120438\u001b[0m\n",
            "59->[283][21-05-21 04:51:55.885 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   59/  143] avg_loss: 0.00111260\u001b[0m\n",
            "60->[283][21-05-21 04:52:06.355 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   60/  143] avg_loss: 0.00314287\u001b[0m\n",
            "61->[283][21-05-21 04:52:17.697 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   61/  143] avg_loss: 0.00117124\u001b[0m\n",
            "62->[283][21-05-21 04:52:28.148 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   62/  143] avg_loss: 0.00101972\u001b[0m\n",
            "63->[283][21-05-21 04:52:38.637 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   63/  143] avg_loss: 0.00110428\u001b[0m\n",
            "64->[283][21-05-21 04:52:49.095 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   64/  143] avg_loss: 0.00108504\u001b[0m\n",
            "65->[283][21-05-21 04:52:59.591 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   65/  143] avg_loss: 0.00086087\u001b[0m\n",
            "66->[283][21-05-21 04:53:10.029 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   66/  143] avg_loss: 0.00086186\u001b[0m\n",
            "67->[283][21-05-21 04:53:20.534 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   67/  143] avg_loss: 0.00076574\u001b[0m\n",
            "68->[283][21-05-21 04:53:30.962 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   68/  143] avg_loss: 0.00120893\u001b[0m\n",
            "69->[283][21-05-21 04:53:41.428 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   69/  143] avg_loss: 0.00072626\u001b[0m\n",
            "70->[283][21-05-21 04:53:51.870 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   70/  143] avg_loss: 0.00105349\u001b[0m\n",
            "71->[283][21-05-21 04:54:03.371 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   71/  143] avg_loss: 0.00078044\u001b[0m\n",
            "72->[283][21-05-21 04:54:13.853 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   72/  143] avg_loss: 0.00083314\u001b[0m\n",
            "73->[283][21-05-21 04:54:24.311 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   73/  143] avg_loss: 0.00074331\u001b[0m\n",
            "74->[283][21-05-21 04:54:34.752 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   74/  143] avg_loss: 0.00088919\u001b[0m\n",
            "75->[283][21-05-21 04:54:45.243 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   75/  143] avg_loss: 0.00125369\u001b[0m\n",
            "76->[283][21-05-21 04:54:55.709 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   76/  143] avg_loss: 0.00081317\u001b[0m\n",
            "77->[283][21-05-21 04:55:06.219 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   77/  143] avg_loss: 0.00099209\u001b[0m\n",
            "78->[283][21-05-21 04:55:16.679 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   78/  143] avg_loss: 0.00090932\u001b[0m\n",
            "79->[283][21-05-21 04:55:27.147 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   79/  143] avg_loss: 0.00084743\u001b[0m\n",
            "80->[283][21-05-21 04:55:37.645 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   80/  143] avg_loss: 0.00092432\u001b[0m\n",
            "81->[283][21-05-21 04:55:49.100 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   81/  143] avg_loss: 0.00084568\u001b[0m\n",
            "82->[283][21-05-21 04:55:59.549 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   82/  143] avg_loss: 0.00096479\u001b[0m\n",
            "83->[283][21-05-21 04:56:10.036 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   83/  143] avg_loss: 0.00081926\u001b[0m\n",
            "84->[283][21-05-21 04:56:20.495 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   84/  143] avg_loss: 0.00090403\u001b[0m\n",
            "85->[283][21-05-21 04:56:30.953 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   85/  143] avg_loss: 0.00078715\u001b[0m\n",
            "86->[283][21-05-21 04:56:41.428 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   86/  143] avg_loss: 0.00104217\u001b[0m\n",
            "87->[283][21-05-21 04:56:51.918 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   87/  143] avg_loss: 0.00097512\u001b[0m\n",
            "88->[283][21-05-21 04:57:02.352 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   88/  143] avg_loss: 0.00105197\u001b[0m\n",
            "89->[283][21-05-21 04:57:12.837 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   89/  143] avg_loss: 0.00108513\u001b[0m\n",
            "90->[283][21-05-21 04:57:23.324 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   90/  143] avg_loss: 0.00094514\u001b[0m\n",
            "91->[283][21-05-21 04:57:34.831 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   91/  143] avg_loss: 0.00098152\u001b[0m\n",
            "92->[283][21-05-21 04:57:45.308 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   92/  143] avg_loss: 0.00070907\u001b[0m\n",
            "93->[283][21-05-21 04:57:55.750 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   93/  143] avg_loss: 0.00110374\u001b[0m\n",
            "94->[283][21-05-21 04:58:06.218 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   94/  143] avg_loss: 0.00121264\u001b[0m\n",
            "95->[283][21-05-21 04:58:16.685 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   95/  143] avg_loss: 0.00117674\u001b[0m\n",
            "96->[283][21-05-21 04:58:27.159 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   96/  143] avg_loss: 0.00084473\u001b[0m\n",
            "97->[283][21-05-21 04:58:37.612 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   97/  143] avg_loss: 0.00127645\u001b[0m\n",
            "98->[283][21-05-21 04:58:47.998 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   98/  143] avg_loss: 0.00108903\u001b[0m\n",
            "99->[283][21-05-21 04:58:58.490 @ train] \u001b[38;5;5mDEBUG: [  3/  3][   99/  143] avg_loss: 0.00064781\u001b[0m\n",
            "100->[283][21-05-21 04:59:08.899 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  100/  143] avg_loss: 0.00120669\u001b[0m\n",
            "101->[283][21-05-21 04:59:20.292 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  101/  143] avg_loss: 0.00096034\u001b[0m\n",
            "102->[283][21-05-21 04:59:30.740 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  102/  143] avg_loss: 0.00084132\u001b[0m\n",
            "103->[283][21-05-21 04:59:41.232 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  103/  143] avg_loss: 0.00082997\u001b[0m\n",
            "104->[283][21-05-21 04:59:51.730 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  104/  143] avg_loss: 0.00121819\u001b[0m\n",
            "105->[283][21-05-21 05:00:02.246 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  105/  143] avg_loss: 0.00101700\u001b[0m\n",
            "106->[283][21-05-21 05:00:12.712 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  106/  143] avg_loss: 0.00096986\u001b[0m\n",
            "107->[283][21-05-21 05:00:23.235 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  107/  143] avg_loss: 0.00123795\u001b[0m\n",
            "108->[283][21-05-21 05:00:33.763 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  108/  143] avg_loss: 0.00121386\u001b[0m\n",
            "109->[283][21-05-21 05:00:44.277 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  109/  143] avg_loss: 0.00104091\u001b[0m\n",
            "110->[283][21-05-21 05:00:54.736 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  110/  143] avg_loss: 0.00125777\u001b[0m\n",
            "111->[283][21-05-21 05:01:06.165 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  111/  143] avg_loss: 0.00078558\u001b[0m\n",
            "112->[283][21-05-21 05:01:16.600 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  112/  143] avg_loss: 0.00100353\u001b[0m\n",
            "113->[283][21-05-21 05:01:27.039 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  113/  143] avg_loss: 0.00111445\u001b[0m\n",
            "114->[283][21-05-21 05:01:37.534 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  114/  143] avg_loss: 0.00101580\u001b[0m\n",
            "115->[283][21-05-21 05:01:47.999 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  115/  143] avg_loss: 0.00084246\u001b[0m\n",
            "116->[283][21-05-21 05:01:58.467 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  116/  143] avg_loss: 0.00091007\u001b[0m\n",
            "117->[283][21-05-21 05:02:08.920 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  117/  143] avg_loss: 0.00089001\u001b[0m\n",
            "118->[283][21-05-21 05:02:19.445 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  118/  143] avg_loss: 0.00082435\u001b[0m\n",
            "119->[283][21-05-21 05:02:29.939 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  119/  143] avg_loss: 0.00108901\u001b[0m\n",
            "120->[283][21-05-21 05:02:40.450 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  120/  143] avg_loss: 0.00084195\u001b[0m\n",
            "121->[283][21-05-21 05:02:51.923 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  121/  143] avg_loss: 0.00119409\u001b[0m\n",
            "122->[283][21-05-21 05:03:02.383 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  122/  143] avg_loss: 0.00109783\u001b[0m\n",
            "123->[283][21-05-21 05:03:12.870 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  123/  143] avg_loss: 0.00139044\u001b[0m\n",
            "124->[283][21-05-21 05:03:23.280 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  124/  143] avg_loss: 0.00095537\u001b[0m\n",
            "125->[283][21-05-21 05:03:33.755 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  125/  143] avg_loss: 0.00111762\u001b[0m\n",
            "126->[283][21-05-21 05:03:44.172 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  126/  143] avg_loss: 0.00111398\u001b[0m\n",
            "127->[283][21-05-21 05:03:54.639 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  127/  143] avg_loss: 0.00071148\u001b[0m\n",
            "128->[283][21-05-21 05:04:05.073 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  128/  143] avg_loss: 0.00107139\u001b[0m\n",
            "129->[283][21-05-21 05:04:15.555 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  129/  143] avg_loss: 0.00071032\u001b[0m\n",
            "130->[283][21-05-21 05:04:26.008 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  130/  143] avg_loss: 0.00068600\u001b[0m\n",
            "131->[283][21-05-21 05:04:37.333 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  131/  143] avg_loss: 0.00112120\u001b[0m\n",
            "132->[283][21-05-21 05:04:47.830 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  132/  143] avg_loss: 0.00125902\u001b[0m\n",
            "133->[283][21-05-21 05:04:58.334 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  133/  143] avg_loss: 0.00090074\u001b[0m\n",
            "134->[283][21-05-21 05:05:08.799 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  134/  143] avg_loss: 0.00146041\u001b[0m\n",
            "135->[283][21-05-21 05:05:19.239 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  135/  143] avg_loss: 0.00124281\u001b[0m\n",
            "136->[283][21-05-21 05:05:29.699 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  136/  143] avg_loss: 0.00123575\u001b[0m\n",
            "137->[283][21-05-21 05:05:40.138 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  137/  143] avg_loss: 0.00193299\u001b[0m\n",
            "138->[283][21-05-21 05:05:50.589 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  138/  143] avg_loss: 0.00064202\u001b[0m\n",
            "139->[283][21-05-21 05:06:01.042 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  139/  143] avg_loss: 0.00086924\u001b[0m\n",
            "140->[283][21-05-21 05:06:11.469 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  140/  143] avg_loss: 0.00140475\u001b[0m\n",
            "141->[283][21-05-21 05:06:22.938 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  141/  143] avg_loss: 0.00086202\u001b[0m\n",
            "142->[283][21-05-21 05:06:33.376 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  142/  143] avg_loss: 0.00079229\u001b[0m\n",
            "143->[283][21-05-21 05:06:42.146 @ train] \u001b[38;5;5mDEBUG: [  3/  3][  143/  143] avg_loss: 0.00116826\u001b[0m\n",
            "[283][21-05-21 05:06:42.312 @ train] \u001b[38;5;4mINFO: Epoch avg = 0.00102917\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR_NgVQ8jOWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d77f9c7f-86b7-46b1-e537-52d0b9985137"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May 21 06:46:29 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}